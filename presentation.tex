

\documentclass[compress, xcolor=pst]{beamer}
%\documentclass[compress, xcolor=pst, handout]{beamer}
\usepackage{graphicx}
\graphicspath{ {images/} }
\mode<presentation>
\usepackage{amsfonts, amsmath, amssymb, color}
\useoutertheme{smoothbars}
\usecolortheme{dolphin}
\usecolortheme{rose}
\usepackage{chngpage}
%\usepackage{beamerthemesplit}
\usepackage{lscape}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{comment}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usepackage{multimedia}
%% === bibliography packages ===
%\usepackage{natbib}
%\bibliographystyle{natbib}

\setbeamertemplate{navigation symbols}{}

\setbeamersize{description width=0.5cm}
\setbeamertemplate{navigation symbols}{}

%\usepackage{spacingset}
\newcommand\spacingset[1]{\renewcommand{\baselinestretch}%
{#1}\small\normalsize}
\newcommand\tab[1][1cm]{\hspace*{#1}}

\usepackage[plain]{algorithm}
\usepackage{algpascal}
\algdef{SE}{For}{End}[2]{%
  \textkeyword{for} \(#1\) \textkeyword{to} \(#2\) }{%
  \textkeyword{end}}
\algdef{SE}{While}{End}[1]{%
  \textkeyword{while} \(#1\)}{%
  \textkeyword{end}}
\algdef{SE}{If}{EndIf}[1]{%
  \textkeyword{if} \(#1\)}{%
  \textkeyword{end}}

\usepackage{color,colortbl}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\title{Bayesian Optimization of a Wearable Assistive Device Using an Estimator Stopping Process}
\author[]{Charles Liu\\ \texttt{cliu02@g.harvard.edu}}
\institute{IACS, Harvard University}
\date{May 4, 2018}

\begin{document}

\frame{\titlepage}


\section{Introduction}
\begin{frame}
    \frametitle{\textbf{Soft Exosuit}}
	\movie[loop, autostart, showcontrols, height = 0.6\textwidth, width = \textwidth]{}{IMG_4348.MOV}
\end{frame}

\begin{frame}
    \frametitle{\textbf{Process Overview}}
	\begin{figure}
		\centering
		\scalebox{.75}{\input{outlineflow}}
	\end{figure}
\end{frame}

\section{Parameter Selection}
\begin{frame}
	\frametitle{\textbf{Standard Gaussian Process Model}}
	Observations represent underlying process with some Gaussian noise
	\begin{align*}
		y &\sim f + \mathcal{N}(0, \sigma_n^2)\\
		f &\sim \mathbb{G}(0, \kappa)\\
		\kappa(x_i, x_j \vert \sigma_\theta^2, l) &= \sigma_\theta^2 \exp(-\frac{1}{2}d^2(\frac{x_i}{l}, \frac{x_j}{l}))
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Gaussian Process Regression}}
	Given some training data, closed form posterior distribution at any point $x$
	\begin{gather*}
	  \bar{\mu}(x) = K(X, x)^T[K(X, X) + \sigma_n^2 I]^{-1}Y \\
	  \bar{\sigma}^2(x) = \kappa(x, x\vert \theta) - K(X, x)^T[K(X,X) + \sigma_n^2 I]^{-1}K(X,x) \\
	  K(X,x)_i = \kappa(x_i, x\vert \theta)\\
	  K(X,X)_{ij} = \kappa(x_i, x_j\vert \theta),
	\end{gather*}
	where $X = \{x_i\}_{i=1}^n$ and $Y = \{y_i\}_{i=1}^n$. 
\end{frame}

\begin{frame}
	\frametitle{\textbf{$\sigma_\theta^2$ Effect}}
	\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{magn_regression}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Hyperparameter Estimation}}
	\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{hyperparamprob.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Expected Improvement}}
	\begin{align*}
	  EI(x\vert \mathbb{S}) &= \int_\infty^\infty max(0, y^*-y)p(y\vert x)dy\\
	    &= z\bar{\sigma}(x)\Phi(z) + \bar{\sigma}(x)\phi(z)\\
	  z &= \frac{y^* - \bar{\mu}(x) + \xi}{\bar{\sigma}(x)},
	\end{align*}
	where $y^*$ is the best value observed so far, $\Phi(z)$ and $\phi(z)$ are the standard normal CDF and PDF functions, and $\xi$ is a scaling parameter to adjust the tradeoff between exploration-exploitation
\end{frame}

\begin{frame}
	\frametitle{\textbf{Bayesian Optimization}}
	\begin{algorithmic}
	\State \textkeyword{Objective Function} $F(x)$
	\State \textkeyword{Acquisition Function} $g(\mu, \sigma^2)$
	\State \textkeyword{Specify Exploration Points } $\mathbb{E} = \{e_1, e_2, ..., e_n\}$
	\State \textkeyword{Training Samples } $\mathbb{S}$
	\For{i=1}{n}
	  \State $\mathbb{S} = \mathbb{S} \cup \{e_i, F(e_i)\}$
	\End
	\While{t < T}
	  \State Update GP Hyperparameters $\theta$
	  \State Given $f(x\vert \theta, \mathbb{S}) \sim \mathcal{N}(\mu_x, \sigma_x^2)$,
	  \State $x^* = \argmax_{x \in \mathbb{X}} g(\mu_x, \sigma_x^2)$
	  \State $\mathbb{S} = \mathbb{S} \cup \{x^*, F(x^*)\}$
	\End
	\end{algorithmic}
\end{frame}

\section{Metabolic Estimation}
\begin{frame}
	\frametitle{\textbf{Instantaneous Energetic Cost}}
	\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{metabolicestimation.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Kalman Filter}}
	System Dynamics
	\begin{align*}
	  x(t+1) &= F(x(t), v(t), t)\\
	  z(t) &= H(x(t), w(t), t)\\
	\end{align*}

	Update Equations
	\begin{align*}
	  \hat{x}(t) &= \hat{x}(t\vert t-1) + Ky \\
	  P_{x}(t) &= P_{x}(t\vert t-1) - KP_{y}(t\vert t-1) K^T\\
	  K &= P_{xy}(t\vert t-1) P_{y}^{-1}(t\vert t-1)\\
	  y &= z(t) - H(\hat{x}(t\vert t-1) , w(t), t)
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Unscented Transform}}
	\vspace{-2em}
	\begin{align*}
	  \chi_0 &= \bar{x}\\
	  \chi_i &= \bar{x} + (\sqrt{(N + \lambda)P_x})_i & i = 1, ..., N \\
	  \chi_i &= \bar{x} - (\sqrt{(N + \lambda)P_x})_{i-N} & i = N + 1, ..., 2N\\
	  W_0^{(m)} &= \lambda /(N + \lambda) \\
	  W_0^{(c)} &= \lambda /(N + \lambda) + (1- \alpha^2 + \beta)\\
	  W_i^m &= W_i^c = 1/\{(2(N + \lambda))\} & i = 1, ..., 2N,
	\end{align*}
	where $\lambda = \alpha^2(N + \kappa) - N$, and $\alpha$, $\kappa$, and $\beta$ are scaling parameters. Given $y=g(x)$,
	\begin{align*}
	  \bar{y} &\approx \sum_{i=0}^{2N} W_i^{(m)}g(\chi_i)\\
	  P_y &\approx \sum_{i=0}^{2N} W_i^{(c)}(g(\chi_i) - \bar{y})(g(\chi_i) - \bar{y})^T
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{\textbf{UKF Model}}
	Time constants $\tau_0, \tau$ characterizing rate of change of cost constants $c_0, c$
	\begin{align*}
		x &= [c_0 \text{ } c \text{ } \tau_0 \text{ } \tau]\\
	    F(x(t), v(t), t) &= x(t) + v(t)\\
	    H(x(t), w(t), t) &= c(1-e^{\frac{-t}{\tau}}) + c_0e^{\frac{-t}{\tau_0}} + w(t)
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Measurement Noise}}
	\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{measurementnoise.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Estimator in Subject Trials}}
	\begin{figure}[t]
	\centering
	\includegraphics[width=\textwidth]{subjcostest.png}
	\end{figure}
\end{frame}

\section{Stopping Models}
\begin{frame}
	\frametitle{\textbf{Stopping Problem Formulation}}
	\begin{table}
		\centering
		\begin{tabular}{ |c  c| }
		  \hline&\\
		  $N$ & Finite horizon\\
		  &\\
		  $X_t$ & State at time $t$\\
		  &\\
		  $P(X_t \vert X_{t-1})$ & State transitions, typically Markovian\\
		  &\\
		  $\lambda$ & Discount Factor $\in (0, 1]$\\
		  &\\
		  $r(X)$ & Bounded reward function for continuing at state $X$\\
		  &\\
		  $g(X)$ & Bounded reward function for stopping at state $X$\\
		  &\\
		  \hline
		\end{tabular}
		\end{table}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Optimal Stopping Point}}
	Via backward induction
	\begin{align*}
	  J_N(x) &= g(x)\\
	  J_n(x) &= max\{g(x), r(x) + \lambda\mathbb{E}_{P(y\vert x)}[J_{n+1}(y)]\}
	\end{align*}
	Optimal stopping point
	\begin{align*}
	  \tau = \min_{t}J_t(X_t) = g(X_t)
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Distribution of Interest}}
	Given
	\begin{align*}
		\text{Current Estimate: } \hat{x}_t &\sim \mathcal{N}(\mu_{x_t}, \sigma^2_{x_t})\\
		\text{Best Estimate: } \hat{x}^* &\sim \mathcal{N}(\mu_{x^*}, \sigma^2_{x^*})
	\end{align*}
	We are concerned with
	\begin{align*}
	    \hat{x}_t - \hat{x}^* &\sim \mathcal{N}(\mu, \sigma^2)\\
	    \mu &= \mu_{x_t} - \mu_{x^*}\\
	    \sigma^2 &= \sigma^2_{x_t} + \sigma^2_{x^*}
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{\textbf{$\sigma$-Offset Model}}
	\begin{align*}
	  X_t &= \mu\\
	  P(X_t \vert X_{t-1}) &= P(X_t) \sim \mathcal{N}(\mu, \sigma^2)\\
	  r(x) &= K\sigma-x\\
	  g(x) &= 0
	\end{align*}
	Stopping condition $X_t > K\sigma$
\end{frame}

\begin{frame}
	\frametitle{\textbf{Success/Failure Model}}
	Define success as
	\begin{align*}
		\Phi(\frac{\mu}{\sigma}) > K,
	\end{align*}
	for risk tolerance $K$. Define model as

	\begin{align*}
	  X_t &= (\alpha_t + \alpha_0, \beta_t + \beta_0) \\
	  P(X_{t+1}) &=
	  \begin{cases}
	      (\alpha_t + \alpha_0 + 1, \beta_t + \beta_0)
	      \\ \tab\text{w.p. } \frac{\alpha_t + \alpha_0}{\alpha_t + \alpha_0 + \beta_t + \beta_0}\\
	      (\alpha_t + \alpha_0, \beta_t + \beta_0 + 1)
	      \\ \tab\text{w.p. } \frac{\beta_t + \beta_0}{\alpha_t + \alpha_0 + \beta_t + \beta_0}
	  \end{cases}\\
	  r(X_t) &= \frac{\alpha_t + \alpha_0}{\alpha_t + \alpha_0 + \beta_t + \beta_0},
	\end{align*}
	with smoothing priors $\alpha_0,\beta_0$ and success/failures $\alpha_t,\beta_t$
\end{frame}

\begin{frame}
	\frametitle{\textbf{Multi-Armed Bandit Problem}}
	Which is the better option?
	\begin{itemize}
		\item Option 1: 20 successes, 20 failures
		\item Option 2: 3 successes, 4 failures
	\end{itemize}
	Define Gittins Index as
	\begin{gather*}
	  \nu(x) = (1-\lambda)\min_{K} \{J_0(x) = g(x) = K\}\\
	  \nu((30, 30)) = 0.5133\\
	  \nu((4, 6)) = 0.5289
	\end{gather*}

	In the case of single option, must set another threshold $\nu(x) < V$
\end{frame}

\begin{frame}
	\frametitle{\textbf{Adaptive Threshold}}
	Use the exploration phase of Bayesian optimization to tune thresholds in either model, with final distribution for each point as "best" value. Consider a window of values at time $t$
	\begin{table}
    \centering
    \begin{tabular}{|c|c|>{\columncolor[gray]{0.8}}c|>{\columncolor[gray]{0.8}}c|>{\columncolor[gray]{0.8}}c|c|c|c|c|c}
        \hline
        $e_{00}$&$e_{01}$&$e_{02}$&$e_{03}$&$e_{04}$&$e_{05}$&$e_{06}$&$e_{07}$&$e_{08}$&$e_{09}$\\\hline
        $e_{10}$&$e_{11}$&$e_{12}$&$e_{13}$&$e_{14}$&$e_{15}$&$e_{16}$&$e_{17}$&$e_{18}$&$e_{19}$\\\hline
        $e_{20}$&$e_{21}$&$e_{22}$&$e_{23}$&$e_{24}$&$e_{25}$&$e_{26}$&$e_{27}$&$e_{28}$&$e_{29}$\\
    \end{tabular}
    $\cdots$\\
    \vspace{0.5em}
    $\vdots$
	\end{table}
	Use most risk averse threshold in window: max $\sigma$-offset, min for Gittins
\end{frame}

\section{Results}
\begin{frame}
	\frametitle{\textbf{Hip-Only Trials}}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Multi-Joint Trials}}
\end{frame}

\section{Conclusion}
\begin{frame}
	\frametitle{\textbf{Future Work}}
\end{frame}

\begin{frame}
	\frametitle{\textbf{Acknowledgements}}
\end{frame}


\begin{comment}
\begin{frame}
\frametitle{\textbf{Include a graphic}}
\begin{figure}[htb]
\spacingset{1}
\centerline{\includegraphics[scale=.40]{data/postprocessing/AvatarSelectionPlot-Role2.pdf}}
\end{figure}
\end{frame}
\end{comment}


%this way you can have a bibliography in your slides.
%\begin{comment}
%\begin{frame}[allowframebreaks]
%\def\newblock{}
%\bibliography{TingleyBib}
%\end{frame}
%\end{comment}



\end{document}